@online{HKC.2024,
  organization = {Herrenknecht AG},
  title = {Herrenknecht.Connected},
  date = {2024-05-22},
  url = {https://www.herrenknecht.com/en/services/herrenknechtconnected/}
}

% This file was created with Citavi 6.17.0.0

@misc{Bai.04.03.2018,
 abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .},
 author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
 date = {04.03.2018},
 title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks  for Sequence Modeling},
 url = {http://arxiv.org/pdf/1803.01271},
 keywords = {Bib},
 file = {Bai, Kolter et al. 04.03.2018 - An Empirical Evaluation of Generic:Attachments/Bai, Kolter et al. 04.03.2018 - An Empirical Evaluation of Generic.pdf:application/pdf}
}


@article{BoZong.2018,
 abstract = {An end-to-end trained deep neural network that leverages Gaussian Mixture Modeling to perform density estimation and unsupervised anomaly detection in a low-dimensional space learned by deep autoencoder.},
 author = {{Bo Zong} and {Qi Song} and {Martin Renqiang Min} and {Wei Cheng} and {Cristian Lumezanu} and {Daeki Cho} and {Haifeng Chen}},
 year = {2018},
 title = {Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection},
 url = {https://openreview.net/forum?id=BJJLHbb0-},
 keywords = {Bib},
 journal = {International Conference on Learning Representations},
 file = {Bo Zong, Qi Song et al. 2018 - Deep Autoencoding Gaussian Mixture Model:Attachments/Bo Zong, Qi Song et al. 2018 - Deep Autoencoding Gaussian Mixture Model.pdf:application/pdf}
}


@article{Breunig.2000,
 abstract = {PDF | For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more... | Find, read and cite all the research you need on ResearchGate},
 author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J{\"o}rg},
 year = {2000},
 title = {LOF},
 url = {https://www.researchgate.net/publication/221214719_LOF_Identifying_Density-Based_Local_Outliers},
 keywords = {Bib},
 pages = {93--104},
 volume = {29},
 number = {2},
 issn = {0163-5808},
 journal = {Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, May 16-18, 2000, Dallas, Texas, USA},
 doi = {10.1145/342009.335388},
 file = {Breunig, Kriegel et al. 2000 - LOF:Attachments/Breunig, Kriegel et al. 2000 - LOF.pdf:application/pdf}
}


@misc{Chen.2021,
 abstract = {Many real-world IoT systems, which include a variety of internet-connected sensory devices, produce substantial amounts of multivariate time series data. Meanwhile, vital IoT infrastructures like smart power grids and water distribution networks are frequently targeted by cyber-attacks, making anomaly detection an important study topic. Modeling such relatedness is, nevertheless, unavoidable for any efficient and effective anomaly detection system, given the intricate topological and nonlinear connections that are originally unknown among sensors. Furthermore, detecting anomalies in multivariate time series is difficult due to their temporal dependency and stochasticity. This paper presented GTA, a new framework for multivariate time series anomaly detection that involves automatically learning a graph structure, graph convolution, and modeling temporal dependency using a Transformer-based architecture. The connection learning policy, which is based on the Gumbel-softmax sampling approach to learn bi-directed links among sensors directly, is at the heart of learning graph structure. To describe the anomaly information flow between network nodes, we introduced a new graph convolution called Influence Propagation convolution. In addition, to tackle the quadratic complexity barrier, we suggested a multi-branch attention mechanism to replace the original multi-head self-attention method. Extensive experiments on four publicly available anomaly detection benchmarks further demonstrate the superiority of our approach over alternative state-of-the-arts. Codes are available at this https URL.},
 author = {Chen, Zekai and Chen, Dingshuo and Zhang, Xiao and Yuan, Zixuan and Cheng, Xiuzhen},
 date = {2022},
 title = {Learning Graph Structures With Transformer for Multivariate Time-Series Anomaly Detection in IoT},
 url = {http://arxiv.org/pdf/2104.03466},
 keywords = {Bib},
 number = {12},
 doi = {10.1109/JIOT.2021.3100509},
 file = {Chen, Chen et al. 2021 - Learning Graph Structures With Transformer:Attachments/Chen, Chen et al. 2021 - Learning Graph Structures With Transformer.pdf:application/pdf}
}


@article{ChenQiu.2022,
 abstract = {Latent Outlier Exposure for Anomaly Detection with Contaminated DataChen Qiu,~Aodong Li,~Marius Kloft,~Maja Rudolph,~Stephan MandtAnomaly...},
 author = {{Chen Qiu} and {Aodong Li} and {Marius Kloft} and {Maja Rudolph} and {Stephan Mandt}},
 year = {2022},
 title = {Latent Outlier Exposure for Anomaly Detection with Contaminated Data},
 url = {https://proceedings.mlr.press/v162/qiu22b.html},
 keywords = {Bib},
 pages = {18153--18167},
 issn = {2640-3498},
 journal = {International Conference on Machine Learning},
 file = {Chen Qiu, Aodong Li et al. 2022 - Latent Outlier Exposure for Anomaly:Attachments/Chen Qiu, Aodong Li et al. 2022 - Latent Outlier Exposure for Anomaly.pdf:application/pdf}
}


@article{Choi.2021,
 abstract = {PDF | As industries become automated and connectivity technologies advance, a wide range of systems continues to generate massive amounts of data. Many... | Find, read and cite all the research you need on ResearchGate},
 author = {Choi, Kukjin and Yi, Jihun and Park, Changhwa and Yoon, Sungroh},
 year = {2021},
 title = {Deep Learning for Anomaly Detection in Time-Series Data: Review, Analysis, and Guidelines},
 url = {https://www.researchgate.net/publication/354155314_Deep_Learning_for_Anomaly_Detection_in_Time-Series_Data_Review_Analysis_and_Guidelines},
 keywords = {Add to main;Bib;good},
 pages = {120043--120065},
 volume = {9},
 number = {99},
 issn = {2169-3536},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2021.3107975},
 file = {Choi, Yi et al. 2021 - Deep Learning for Anomaly Detection:Attachments/Choi, Yi et al. 2021 - Deep Learning for Anomaly Detection.pdf:application/pdf}
}


@article{D.Berndt.1994,
 abstract = {Preliminary experiments with a dynamic programming approach to pattern detection in databases, based on the dynamic time warping technique used in the speech recognition field, are described. Knowledge discovery in databases presents many interesting challenges within the context of providing computer tools for exploring large data archives. Electronic data repositories are growing quickly and contain data from commercial, scientific, and other domains. Much of this data is inherently temporal, such as stock prices or NASA telemetry data. Detecting patterns in such data streams or time series is an important knowledge discovery task. This paper describes some preliminary experiments with a dynamic programming approach to the problem. The pattern detection algorithm is based on the dynamic time warping technique used in the speech recognition field.},
 author = {{D. Berndt} and {J. Clifford}},
 year = {1994},
 title = {Using Dynamic Time Warping to Find Patterns in Time Series},
 url = {https://www.semanticscholar.org/paper/Using-Dynamic-Time-Warping-to-Find-Patterns-in-Time-Berndt-Clifford/1ac57524ba2d2a69c1bb6defed7352a06fd7050d},
 keywords = {Bib},
 journal = {KDD Workshop}
}


@article{Deng.2021,
 abstract = {Given high-dimensional time series data (e.g., sensor data), how can we detect anomalous events, such as system faults and attacks? More challengingly, how can we do this in a way that captures complex inter-sensor relationships, and detects and explains anomalies which deviate from these relationships? Recently, deep learning approaches have enabled improvements in anomaly detection in high-dimensional datasets; however, existing methods do not explicitly learn the structure of existing relationships between variables, or use them to predict the expected behavior of time series. Our approach combines a structure learning approach with graph neural networks, additionally using attention weights to provide explainability for the detected anomalies. Experiments on two real-world sensor datasets with ground truth anomalies show that our method detects anomalies more accurately than baseline approaches, accurately captures correlations between sensors, and allows users to deduce the root cause of a detected anomaly.},
 author = {Deng, Ailin and Hooi, Bryan},
 year = {2021},
 title = {Graph Neural Network-Based Anomaly Detection in Multivariate Time Series},
 url = {https://ojs.aaai.org/index.php/AAAI/article/view/16523},
 keywords = {Bib},
 pages = {4027--4035},
 volume = {35},
 number = {5},
 issn = {2374-3468},
 journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
 doi = {10.1609/aaai.v35i5.16523},
 file = {Deng, Hooi 2021 - Graph Neural Network-Based Anomaly Detection:Attachments/Deng, Hooi 2021 - Graph Neural Network-Based Anomaly Detection.pdf:application/pdf}
}


@article{Hochreiter.1997,
 abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
 author = {Hochreiter, S. and Schmidhuber, J.},
 year = {1997},
 title = {Long short-term memory},
 keywords = {Bib},
 pages = {1735--1780},
 volume = {9},
 number = {8},
 issn = {0899-7667},
 journal = {Neural computation},
 doi = {10.1162/neco.1997.9.8.1735}
}


@article{Jin.2016,
 author = {Jin, Xiaohang and Sun, Yi and Que, Zijun and Wang, Yu and Chow, Tommy W. S.},
 year = {2016},
 title = {Anomaly Detection and Fault Prognosis for Bearings},
 keywords = {Bib},
 pages = {2046--2054},
 volume = {65},
 number = {9},
 issn = {0018-9456},
 journal = {IEEE Transactions on Instrumentation and Measurement},
 doi = {10.1109/TIM.2016.2570398}
}


@article{Kim.2023,
 abstract = {Most deep anomaly detection models are based on learning normality from datasets due to the difficulty of defining abnormality by its diverse and inconsistent nature. Therefore, it has been a common practice to learn normality under the assumption that anomalous data are absent in a training dataset, which we call normality assumption. However, in practice, the normality assumption is often violated due to the nature of real data distributions that includes anomalous tails, i.e., a contaminated dataset. Thereby, the gap between the assumption and actual training data affects detrimentally in learning of an anomaly detection model. In this work, we propose a learning framework to reduce this gap and achieve better normality representation. Our key idea is to identify sample-wise normality and utilize it as an importance weight, which is updated iteratively during the training. Our framework is designed to be model-agnostic and hyperparameter insensitive so that it applies to a wide range of existing methods without careful parameter tuning. We apply our framework to three different representative approaches of deep anomaly detection that are classified into one-class classification-, probabilistic model-, and reconstruction-based approaches. In addition, we address the importance of a termination condition for iterative methods and propose a termination criterion inspired by the anomaly detection objective. We validate that our framework improves the robustness of the anomaly detection models under different levels of contamination ratios on five anomaly detection benchmark datasets and two image datasets. On various contaminated datasets, our framework improves the performance of three representative anomaly detection methods, measured by area under the ROC curve.},
 author = {Kim, Minkyung and Yu, Jongmin and Kim, Junsik and Oh, Tae-Hyun and Choi, Jun Kyun},
 year = {2023},
 title = {An Iterative Method for Unsupervised Robust Anomaly Detection Under Data Contamination},
 keywords = {Bib},
 volume = {PP},
 journal = {IEEE transactions on neural networks and learning systems},
 doi = {10.1109/TNNLS.2023.3267028},
 file = {Kim, Yu et al. 2023 - An Iterative Method for Unsupervised:Attachments/Kim, Yu et al. 2023 - An Iterative Method for Unsupervised.pdf:application/pdf}
}


@article{M.Ester.1996,
 abstract = {DBSCAN, a new clustering algorithm relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape, is presented which requires only one input parameter and supports the user in determining an appropriate value for it. Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLARANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.},
 author = {{M. Ester} and {H. Kriegel} and {J. Sander} and {Xiaowei Xu}},
 year = {1996},
 title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},
 url = {https://www.semanticscholar.org/paper/A-Density-Based-Algorithm-for-Discovering-Clusters-Ester-Kriegel/5c8fe9a0412a078e30eb7e5eeb0068655b673e86},
 keywords = {Bib},
 journal = {Knowledge Discovery and Data Mining}
}


@article{RueiJieHsieh.2019,
 abstract = {An unsupervised real-time anomaly detection algorithm based on LSTM-based Auto-Encoder is proposed to improve the anomaly detection accuracy at an earlier stage of production line, so that cost and time wasted by possible production failures can be reduced. The emergence of IoT and AI has brought revolutionary change in various application domains. One of them is Industry 4.0, also called Smart Manufacturing, which aims to achieve highly flexible and automated production processes. In this paper, we study a use case of anomaly detection in smart manufacturing using the real data collected from the sensing devices of a factory production line. Our goal is to improve the anomaly detection accuracy at an earlier stage of production line, so that cost and time wasted by possible production failures can be reduced. To overcome the limited and irregular anomaly patterns found from our multivariate sensor dataset, we proposed an unsupervised real-time anomaly detection algorithm based on LSTM-based Auto-Encoder. Our evaluations show that our approach achieved almost 90{\%} accuracy for both precision and recall while other classification or regression based methods only reached 70{\%}{\~{}}85{\%}.},
 author = {{Ruei-Jie Hsieh} and {Jerry Chou} and {Chih-Hsiang Ho}},
 year = {2019},
 title = {Unsupervised Online Anomaly Detection on Multivariate Sensing Time Series Data for Smart Manufacturing},
 url = {https://www.semanticscholar.org/paper/Unsupervised-Online-Anomaly-Detection-on-Sensing-Hsieh-Chou/f2dc4fb527a4165efbed142338d00cd56d61d8b7},
 keywords = {Bib},
 journal = {IEEE International Conference on Service-Oriented Computing and Applications}
}


@misc{Saleh.01.10.2021,
 abstract = {We review the rapidly growing literature on auxiliary information-based (AIB) process monitoring methods. Under this approach, there is an assumption that the auxiliary variable, which is correlated with the quality variable of interest, has a known mean, or some other parameter, which cannot change over time. We demonstrate that violations of this assumption can have serious adverse effects both when the process is stable and when there has been a process shift. Some process shifts can become undetectable. We also show that the basic AIB approach is a special case of simple linear regression profile monitoring. The AIB charting techniques require strong assumptions. Based on our results, we warn against the use of AIB approach in quality control applications.},
 author = {Saleh, Nesma A. and Mahmoud, Mahmoud A. and Woodall, William H. and Knoth, Sven},
 date = {01.10.2021},
 title = {A Review and Critique of Auxiliary Information-Based Process Monitoring  Methods},
 url = {http://arxiv.org/pdf/2110.00198},
 keywords = {Bib},
 file = {Saleh, Mahmoud et al. 01.10.2021 - A Review and Critique:Attachments/Saleh, Mahmoud et al. 01.10.2021 - A Review and Critique.pdf:application/pdf}
}


@article{Shang.2023,
 abstract = {Machine anomaly detection is the task of detecting machine abnormal condition via the collected monitoring data. Recently, increasing attention has focused on autoencoder (AE) based unsupervised anomaly detection (UAD) for mechanical equipment. Typically, the UAD is based on the assumption that all of the training data are normal. In real scenarios, however, the raw monitoring data may be polluted by abnormal data due to machine failures, environmental noise, sensor failures, etc. Without effective regularization, AE-based methods would overfit these polluted data. To address this issue, we design an effective loss, called core loss, which can perform AE-based UAD in a both model-agnostic and end-to-end manner under data pollution. First, we experimentally observe that the AE shows the self-clean characteristic (SCC) under data pollution, i.e., the network will prioritize learning the normal data from the polluted training data. Next, we focus on the core samples, which make up a clean and representative subset of the unlabeled data. Based on the SCC, we propose the core prior that reconstruction errors in the middle with high density correspond to the core samples. Finally, to enhance the SCC, the core loss exploits the core prior to effectively mine and learn the core samples. The experimental results show that the core loss can effectively improve the performance of different network structures on both clean and polluted data. The corresponding Python codes are available at https://github.com/albertszg/Coreloss.},
 author = {Shang, Zuogang and Zhao, Zhibin and Yan, Ruqiang and Chen, Xuefeng},
 year = {2023},
 title = {Core loss: Mining core samples efficiently for robust machine anomaly detection against data pollution},
 url = {https://www.sciencedirect.com/science/article/pii/S0888327022011141},
 keywords = {Bib},
 pages = {110046},
 volume = {189},
 issn = {0888-3270},
 journal = {Mechanical Systems and Signal Processing},
 doi = {10.1016/j.ymssp.2022.110046}
}


